{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1\n",
    "Marissa Wiener <br> 9/23/2016 <br><br>See code and explanations below for problems associated with Project 01.  Problem numbers and answers are denoted in **boldface**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 - Word Count \n",
    "#### Part A. Characters in Little Women"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First retrieve women.txt (if not already downloaded), which contains the text of *Little Women*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-20 01:54:06--  https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/women.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.20.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.20.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1053440 (1.0M) [text/plain]\n",
      "Saving to: ‘women.txt’\n",
      "\n",
      "women.txt           100%[=====================>]   1.00M  --.-KB/s   in 0.06s  \n",
      "\n",
      "2016-09-20 01:54:06 (17.1 MB/s) - ‘women.txt’ saved [1053440/1053440]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/women.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below shows the number of times where Amy, Beth, Jo, and Meg are mentioned respectively in *Little Women*. The code first separates each word in the text to its own line, transforms all text to lower case, sorts data, and finally finds unique counts for each of the words. **Jo is mentioned 1362 times, Meg is mentioned 686 times, Amy is mentioned 652 times, and Beth is mentioned 467 times.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WC  Name\n",
      "   ---------\n",
      "    652 amy\n",
      "    467 beth\n",
      "   1362 jo\n",
      "    686 meg\n"
     ]
    }
   ],
   "source": [
    "!echo '    WC  Name'\n",
    "!echo '   ---------'\n",
    "!cat women.txt | grep -oE '\\w{{2,}}'| tr [:upper:] [:lower:] | grep -w 'jo\\|beth\\|meg\\|amy'| sort | uniq -c "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part B. Juliet and Romeo in Romeo and Juliet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, retrieve romeo.txt (if not already downloaded), which contains the text of *Romeo and Juliet*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-19 23:24:50--  https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/romeo.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.20.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.20.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 178983 (175K) [text/plain]\n",
      "Saving to: ‘romeo.txt’\n",
      "\n",
      "romeo.txt           100%[=====================>] 174.79K  --.-KB/s   in 0.02s  \n",
      "\n",
      "2016-09-19 23:24:50 (7.82 MB/s) - ‘romeo.txt’ saved [178983/178983]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/romeo.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to figure out how characters are assigned each line. From the output below, it is shown that for Romeo's lines, \"Rom.\" is used, and similarly, \"Jul.\" is used for Juliet's lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:﻿The Project Gutenberg EBook of Romeo and Juliet, by William Shakespeare\r",
      "\r\n",
      "9:Title: Romeo and Juliet\r",
      "\r\n",
      "19:*** START OF THIS PROJECT GUTENBERG EBOOK ROMEO AND JULIET ***\r",
      "\r\n",
      "46:The Tragedy of Romeo and Juliet\r",
      "\r\n",
      "66:THE TRAGEDY OF ROMEO AND JULIET\r",
      "\r\n",
      "87:  Romeo, son to Montague.\r",
      "\r\n",
      "91:  Mercutio, kinsman to the Prince and friend to Romeo.\r",
      "\r\n",
      "93:  Benvolio, nephew to Montague, and friend to Romeo\r",
      "\r\n",
      "101:  Balthasar, servant to Romeo.\r",
      "\r\n",
      "109:  Peter, servant to Juliet's nurse.\r",
      "\r\n",
      "122:  Juliet, daughter to Capulet.\r",
      "\r\n",
      "124:  Nurse to Juliet.\r",
      "\r\n",
      "351:  M. Wife. O, where is Romeo? Saw you him to-day?\r",
      "\r\n",
      "398:                       Enter Romeo.\r",
      "\r\n",
      "417:  Ben. It was. What sadness lengthens Romeo's hours?\r",
      "\r\n",
      "468:    This is not Romeo, he's some other where.\r",
      "\r\n",
      "587:                   Enter Benvolio and Romeo.\r",
      "\r\n",
      "603:  Ben. Why, Romeo, art thou mad?\r",
      "\r\n",
      "688:    God forbid! Where's this girl? What, Juliet!\r",
      "\r\n",
      "690:                         Enter Juliet.\r",
      "\r\n",
      "768:    I came to talk of. Tell me, daughter Juliet,\r",
      "\r\n",
      "824:    Juliet, the County stays.\r",
      "\r\n",
      "835:Enter Romeo, Mercutio, Benvolio, with five or six other Maskers;\r",
      "\r\n",
      "854:  Mer. Nay, gentle Romeo, we must have you dance.\r",
      "\r\n",
      "1012:              Juliet, Tybalt, and all the Guests\r",
      "\r\n",
      "1076:  Cap. Young Romeo is it?\r",
      "\r\n",
      "1078:  Tyb. 'Tis he, that villain Romeo.\r",
      "\r\n",
      "1170:                              Exeunt [all but Juliet and Nurse].\r",
      "\r\n",
      "1187:  Nurse. His name is Romeo, and a Montague,\r",
      "\r\n",
      "1199:                                     One calls within, 'Juliet.'\r",
      "\r\n",
      "1215:    With tender Juliet match'd, is now not fair.\r",
      "\r\n",
      "1216:    Now Romeo is belov'd, and loves again,\r",
      "\r\n",
      "1234:Enter Romeo alone.\r",
      "\r\n",
      "1244:  Ben. Romeo! my cousin Romeo! Romeo!\r",
      "\r\n",
      "1253:    Romeo! humours! madman! passion! lover!\r",
      "\r\n",
      "1287:    O, Romeo, that she were, O that she were\r",
      "\r\n",
      "1289:    Romeo, good night. I'll to my truckle-bed;\r",
      "\r\n",
      "1303:Enter Romeo.\r",
      "\r\n",
      "1308:                     Enter Juliet above at a window.\r",
      "\r\n",
      "1311:    It is the East, and Juliet is the sun!\r",
      "\r\n",
      "1346:  Jul. O Romeo, Romeo! wherefore art thou Romeo?\r",
      "\r\n",
      "1360:    So Romeo would, were he not Romeo call'd,\r",
      "\r\n",
      "1362:    Without that title. Romeo, doff thy name;\r",
      "\r\n",
      "1368:    Henceforth I never will be Romeo.\r",
      "\r\n",
      "1381:    Art thou not Romeo, and a Montague?\r",
      "\r\n",
      "1424:    They say Jove laughs. O gentle Romeo,\r",
      "\r\n",
      "1490:                       Enter Juliet above.\r",
      "\r\n",
      "1493:  Jul. Three words, dear Romeo, and good night indeed.\r",
      "\r\n",
      "1520:                     Enter Juliet again, [above].\r",
      "\r\n",
      "1523:  Jul. Hist! Romeo, hist! O for a falconer's voice\r",
      "\r\n",
      "1528:    With repetition of my Romeo's name.\r",
      "\r\n",
      "1529:    Romeo!\r",
      "\r\n",
      "1535:  Jul. Romeo!\r",
      "\r\n",
      "1616:                        Enter Romeo.\r",
      "\r\n",
      "1632:    Our Romeo hath not been in bed to-night.\r",
      "\r\n",
      "1714:  Mer. Where the devil should this Romeo be?\r",
      "\r\n",
      "1727:  Ben. Romeo will answer it.\r",
      "\r\n",
      "1734:  Mer. Alas, poor Romeo, he is already dead! stabb'd with a white\r",
      "\r\n",
      "1759:                               Enter Romeo.\r",
      "\r\n",
      "1762:  Ben. Here comes Romeo! here comes Romeo!\r",
      "\r\n",
      "1769:    but not to the purpose. Signior Romeo, bon jour! There's a French\r",
      "\r\n",
      "1829:    art thou sociable, now art thou Romeo; now art thou what thou art, by\r",
      "\r\n",
      "1877:    young Romeo?\r",
      "\r\n",
      "1879:  Rom. I can tell you; but young Romeo will be older when you\r",
      "\r\n",
      "1907:    Romeo, will you come to your father's? We'll to dinner thither.\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!grep -win 'Romeo\\|Juliet' romeo.txt | head -65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the output below, **Romeo has 163 lines and Juliet has 117 lines**.  These results were obtained by separating words from the play into their own lines, filtering for cases of \"Rom\" or \"Jul\" since this the syntax for which lines are assigned, sorting output and counting the instances of Juliet and Romeo lines respectively. One thing to note is that the code used to separate each word of the text onto different lines, it removes all punctuation before or after a particular word.  Therefore, when we filter for these words, the \".\" after Rom/Jul is unnecessary to include. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WC  Name\n",
      "   ---------\n",
      "    117 Jul\n",
      "    163 Rom\n"
     ]
    }
   ],
   "source": [
    "!echo '    WC  Name'\n",
    "!echo '   ---------'\n",
    "!cat romeo.txt | grep -oE '\\w{{2,}}'|grep -w 'Rom\\|Jul'| sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 - Capital Bikeshare\n",
    "#### Part A. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, retrieve zip file which contains Capital Bikeshare data from 1Q16, unzip it (if this has not been done yet), and rename it to q1.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-20 00:42:41--  https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/2016q1.csv.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.20.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.20.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10643003 (10M) [application/octet-stream]\n",
      "Saving to: ‘2016q1.csv.zip’\n",
      "\n",
      "2016q1.csv.zip      100%[=====================>]  10.15M  57.0MB/s   in 0.2s   \n",
      "\n",
      "2016-09-20 00:42:42 (57.0 MB/s) - ‘2016q1.csv.zip’ saved [10643003/10643003]\n",
      "\n",
      "Archive:  2016q1.csv.zip\n",
      "  inflating: 2016q1.csv              \n"
     ]
    }
   ],
   "source": [
    "!wget 'https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/2016q1.csv.zip'\n",
    "!unzip 2016q1.csv.zip\n",
    "!mv 2016q1.csv q1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use the following code to note the column names and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1: Duration (ms)\r\n",
      "  2: Start date\r\n",
      "  3: End date\r\n",
      "  4: Start station number\r\n",
      "  5: Start station\r\n",
      "  6: End station number\r\n",
      "  7: End station\r\n",
      "  8: Bike number\r\n",
      "  9: Member Type\r\n"
     ]
    }
   ],
   "source": [
    "!csvcut -n q1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below takes column 5 of the csv file q1, which is the start station column, sorts the file by starting station, counts the number of starts for each of the stations.  It then sorts in descending order of frequency and prints the 10 most popular departing stations in 1Q16. **The 10 most popular stations are Union Station, Massachusetts Ave & Dupont Station, Lincoln Memorial, Jefferson Dr & 14th St SW, Thomas Circle, 15th & P NW, 14th & V NW, New Hampshire and T St NW, Eastern Market Metro, and 17th and Corcoran stations**.  These stations make sense since they are near popular and highly traveled areas of the city. Personally, I have contributed mostly to the frequency of trips starting from 15th & P St NW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Freq  Station Name\n",
      "    ---------------------------------------\n",
      "  13120 Columbus Circle / Union Station\n",
      "   9560 Massachusetts Ave & Dupont Circle NW\n",
      "   9388 Lincoln Memorial\n",
      "   8138 Jefferson Dr & 14th St SW\n",
      "   7479 Thomas Circle\n",
      "   7401 15th & P St NW\n",
      "   6568 14th & V St NW\n",
      "   6491 New Hampshire Ave & T St NW\n",
      "   5649 Eastern Market Metro / Pennsylvania Ave & 7th St SE\n",
      "   5514 17th & Corcoran St NW\n"
     ]
    }
   ],
   "source": [
    "!echo '   Freq  Station Name'\n",
    "!echo '   ------------------------------------------------'\n",
    "!csvcut -c5 q1.csv | sort | uniq -c | sort -rn | head -10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below uses the information above to find the bike number which was most  frequently a departing trip from the most popular departing station, Columbus Circle/Union Station.  It pulls both starting station and bike number from the original csv file, and filters only on trips departing from this station.  From this output, it takes the second column (bike number), sorts data and finds the unique count for each bike number.  The top 12 are displayed below since there was a tie for frequency at 15.  **The bike numbers with the top 10 frequencies were W22227, W21867, W21641, W21538, W21239, W20540, W00714, W22080, W21450, W21076, W00777, and W00288**.  This was suprising and seemed rather low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     17 W22227\r\n",
      "     16 W21867\r\n",
      "     16 W21641\r\n",
      "     16 W21538\r\n",
      "     16 W21239\r\n",
      "     16 W20540\r\n",
      "     16 W00714\r\n",
      "     15 W22080\r\n",
      "     15 W21450\r\n",
      "     15 W21076\r\n",
      "     15 W00777\r\n",
      "     15 W00288\r\n",
      "sort: write failed: standard output: Broken pipe\r\n",
      "sort: write error\r\n"
     ]
    }
   ],
   "source": [
    "!echo '    Freq Bike#'\n",
    "!echo '    ----------'\n",
    "!csvcut -c5,8 q1.csv | grep 'Columbus Circle / Union Station'|csvcut -c2 | sort -n | uniq -c | sort -rn | head -12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below takes column 7 of the csv file q1, which is the end station column, sorts the file by ending station, counts the number of trips ending for each of the stations. It then sorts in descending order of frequency and prints the 10 most popular ending stations in 1Q16. **The 10 most popular stations are Union Station, Massachusetts Ave & Dupont Station, Lincoln Memorial, Jefferson Dr & 14th St SW, 15th & P NW, 14th & V NW, Thomas Circle, New Hampshire and T St NW, 5th & K Street NW, and 17th and Corcoran stations**. These stations are highly correlated to the most popular departing stations, as would be expected considering their locations in the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  13880 Columbus Circle / Union Station\r\n",
      "  11183 Massachusetts Ave & Dupont Circle NW\r\n",
      "   9419 Lincoln Memorial\r\n",
      "   8975 Jefferson Dr & 14th St SW\r\n",
      "   8092 15th & P St NW\r\n",
      "   7267 14th & V St NW\r\n",
      "   6997 Thomas Circle\r\n",
      "   6245 New Hampshire Ave & T St NW\r\n",
      "   5761 5th & K St NW\r\n",
      "   5651 17th & Corcoran St NW\r\n"
     ]
    }
   ],
   "source": [
    "!echo '   Freq  Station Name'\n",
    "!echo '   ------------------------------------------------'\n",
    "!csvcut -c7 q1.csv | csvsort | uniq -c | sort -rn | head -10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below uses the information above to find the bike number which was most frequently to end at the most popular destination station, Columbus Circle/Union Station. It pulls both ending station and bike number from the original csv file, and filters only on trips ending from this station. From this output, it takes the second column (bike number), sorts data and finds the unique count for each bike number. The top 15 are displayed below since there was a tie for frequency at 15. **The bike numbers with the top 10 frequencies were W00485, W22227, W22099, W22080, W21239, W21076, W20425, W00714, W21997, W21867, W21641, W21538, W21450, W20540, and W01439.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Freq Bike#\n",
      "    ----------\n",
      "     18 W00485\n",
      "     17 W22227\n",
      "     16 W22099\n",
      "     16 W22080\n",
      "     16 W21239\n",
      "     16 W21076\n",
      "     16 W20425\n",
      "     16 W00714\n",
      "     15 W21997\n",
      "     15 W21867\n",
      "     15 W21641\n",
      "     15 W21538\n",
      "     15 W21450\n",
      "     15 W20540\n",
      "     15 W01439\n",
      "sort: write failed: standard output: Broken pipe\n",
      "sort: write error\n"
     ]
    }
   ],
   "source": [
    "!echo '    Freq Bike#'\n",
    "!echo '    ----------'\n",
    "!csvcut -c7,8 q1.csv | grep 'Columbus Circle / Union Station'|csvcut -c2 | csvsort | uniq -c | sort -rn | head -15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 - Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get simple python filter from github (if you have not already). Copy filter and rename it for the first each task. These files can be edited to create filters for part A and B of problem 3.\n",
    "<br>    1. word-per-line.py \n",
    "<br>    2. lower.py\n",
    "<br>    3. lwr-rm-stp-wds.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code takes the text of *Little Women*, separates words into separate rows, transforms words to lower case, sorts, counts unique words, sorts in descending order of word count frequency, and displays the 10 most popular words. **The 10 most popular words are and, the, to, a, I, of, her, it, in, and you**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   WC   Word\n",
      "   ---------\n",
      "   8155 and\n",
      "   7689 the\n",
      "   5152 to\n",
      "   4531 a\n",
      "   4003 i\n",
      "   3523 of\n",
      "   3245 her\n",
      "   2774 it\n",
      "   2503 in\n",
      "   2447 you\n",
      "sort: write failed: standard output: Broken pipe\n",
      "sort: write error\n"
     ]
    }
   ],
   "source": [
    "!echo '   WC   Word'\n",
    "!echo '   ---------'\n",
    "!cat women.txt | grep -oE '\\w{{1,}}'|tr '[:upper:]' '[:lower:]' | sort | uniq -c | sort -rn | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first python filter lsted below mimics and replaces the part of the pipe above which separates a word to each line (grep -oE '\\w{{1,}}'). The second converts all of the words to lower case (tr '[:upper:]' '[:lower:]'). The code changes the mode to give everyone execute access to the word-per-line.py and lower.py filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!chmod +x word-per-line.py\n",
    "!chmod +x lower.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below shows a preview of what the word-per-line.py filter does. It takes the first three lines of Little Women and separates each word per line.\n",
    "\n",
    "Note: Wei helped me figure out how to remove the punctuation from each line using the re package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\r\n",
      "Project\r\n",
      "Gutenberg\r\n",
      "EBook\r\n",
      "of\r\n",
      "Little\r\n",
      "Women\r\n",
      "by\r\n",
      "Louisa\r\n",
      "May\r\n",
      "Alcott\r\n",
      "This\r\n",
      "eBook\r\n",
      "is\r\n",
      "for\r\n",
      "the\r\n",
      "use\r\n",
      "of\r\n",
      "anyone\r\n",
      "anywhere\r\n",
      "at\r\n",
      "no\r\n",
      "cost\r\n",
      "and\r\n",
      "with\r\n"
     ]
    }
   ],
   "source": [
    "!head -3 women.txt | ./word-per-line.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add the next python filter lower.py. This filter takes the list of words generated by word-per-line.py and converts each line to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\r\n",
      "project\r\n",
      "gutenberg\r\n",
      "ebook\r\n",
      "of\r\n",
      "little\r\n",
      "women\r\n",
      "by\r\n",
      "louisa\r\n",
      "may\r\n",
      "alcott\r\n",
      "this\r\n",
      "ebook\r\n",
      "is\r\n",
      "for\r\n",
      "the\r\n",
      "use\r\n",
      "of\r\n",
      "anyone\r\n",
      "anywhere\r\n",
      "at\r\n",
      "no\r\n",
      "cost\r\n",
      "and\r\n",
      "with\r\n"
     ]
    }
   ],
   "source": [
    "!head -3 women.txt | ./word-per-line.py | ./lower.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As seen below, when juxtaposing the original command to obtain the most common words with the new python filter method, the same result is obtained.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Way:\n",
      "   WC   Word\n",
      "   ---------\n",
      "   8155 and\n",
      "   7689 the\n",
      "   5152 to\n",
      "   4531 a\n",
      "   4003 i\n",
      "   3523 of\n",
      "   3245 her\n",
      "   2774 it\n",
      "   2503 in\n",
      "   2447 you\n",
      "sort: write failed: standard output: Broken pipe\n",
      "sort: write error\n",
      "\n",
      "With Python Filters:\n",
      "   WC   Word\n",
      "   ---------\n",
      "   8155 and\n",
      "   7689 the\n",
      "   5152 to\n",
      "   4531 a\n",
      "   4003 i\n",
      "   3523 of\n",
      "   3245 her\n",
      "   2774 it\n",
      "   2503 in\n",
      "   2447 you\n",
      "sort: write failed: standard output: Broken pipe\n",
      "sort: write error\n"
     ]
    }
   ],
   "source": [
    "!echo 'Original Way:'\n",
    "!echo '   WC   Word'\n",
    "!echo '   ---------'\n",
    "!cat women.txt | grep -oE '\\w{{1,}}'|tr '[:upper:]' '[:lower:]' | sort | uniq -c | sort -rn | head -10\n",
    "!echo '\\nWith Python Filters:'\n",
    "!echo '   WC   Word'\n",
    "!echo '   ---------'\n",
    "!cat women.txt | ./word-per-line.py | ./lower.py | sort | uniq -c | sort -rn | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to easily obtain a full list of stop words, install the stop-words package (ignore this step if package is already installed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stop-words\n",
      "  Downloading stop-words-2015.2.23.1.tar.gz\n",
      "Building wheels for collected packages: stop-words\n",
      "  Running setup.py bdist_wheel for stop-words ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/22/74/80/77275c2f9f2f1d9841b51e169a38985640a10fbd2711d10791\n",
      "Successfully built stop-words\n",
      "Installing collected packages: stop-words\n",
      "Successfully installed stop-words-2015.2.23.1\n"
     ]
    }
   ],
   "source": [
    "!pip install stop-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python filter listed below mimics and replaces the lower.py filter used before. Instead of just lower-casing all of the words in the file, this filter imports a list of stop words from the stop-words package, compares these words to the words from *Little Women*, and prints the words which are not stop words.  The code changes the mode to give everyone execute access to the lwr-rm-stp-wds.py filter, and shows what the output looks like for the first 3 lines of *Little Women*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project\r\n",
      "gutenberg\r\n",
      "ebook\r\n",
      "little\r\n",
      "women\r\n",
      "louisa\r\n",
      "may\r\n",
      "alcott\r\n",
      "ebook\r\n",
      "use\r\n",
      "anyone\r\n",
      "anywhere\r\n",
      "cost\r\n"
     ]
    }
   ],
   "source": [
    "!chmod +x lwr-rm-stp-wds.py\n",
    "!head -3 women.txt | ./word-per-line.py | ./lwr-rm-stp-wds.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates a list of the top 10 most frequent words which aren't stopwords. **The words are...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1680 t\n",
      "   1495 s\n",
      "   1362 jo\n",
      "    827 said\n",
      "    730 little\n",
      "    725 one\n",
      "    686 meg\n",
      "    652 amy\n",
      "    598 laurie\n",
      "    591 like\n",
      "sort: write failed: standard output: Broken pipe\n",
      "sort: write error\n"
     ]
    }
   ],
   "source": [
    "!cat women.txt | ./word-per-line.py | ./lwr-rm-stp-wds.py | sort | uniq -c | sort -rn | head -25\n"
    "!cat women.txt | grep -oE '\\w{{2,}}' | ./lwr-rm-stp-wds.py | sort | uniq -c | sort -rn | head -25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
